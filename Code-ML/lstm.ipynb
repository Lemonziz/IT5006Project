{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set random seed for reproducibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Device configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and prepare data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a unique location identifier and time key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['location_id', 'Year', 'Month', 'crime_count', 'weekday', 'weekend',\n",
       "       'morning', 'afternoon', 'evening', 'night', 'holiday_num', 'num_days',\n",
       "       'morning_rate', 'afternoon_rate', 'evening_rate', 'night_rate',\n",
       "       'sin_month', 'cos_month', 'time_id', 'crime_pct_change'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"rnn_data_train.csv\")\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_id</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>crime_count</th>\n",
       "      <th>weekday</th>\n",
       "      <th>weekend</th>\n",
       "      <th>morning</th>\n",
       "      <th>afternoon</th>\n",
       "      <th>evening</th>\n",
       "      <th>night</th>\n",
       "      <th>...</th>\n",
       "      <th>morning_rate</th>\n",
       "      <th>afternoon_rate</th>\n",
       "      <th>evening_rate</th>\n",
       "      <th>night_rate</th>\n",
       "      <th>sin_month</th>\n",
       "      <th>cos_month</th>\n",
       "      <th>time_id</th>\n",
       "      <th>crime_pct_change</th>\n",
       "      <th>location_idx</th>\n",
       "      <th>time_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>24217</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>24218</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>24219</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>24220</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>36</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>24221</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2428</th>\n",
       "      <td>99</td>\n",
       "      <td>2024</td>\n",
       "      <td>8</td>\n",
       "      <td>91</td>\n",
       "      <td>70</td>\n",
       "      <td>21</td>\n",
       "      <td>33</td>\n",
       "      <td>46</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.362637</td>\n",
       "      <td>0.505495</td>\n",
       "      <td>0.087912</td>\n",
       "      <td>0.043956</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>24296</td>\n",
       "      <td>0.022472</td>\n",
       "      <td>31</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2429</th>\n",
       "      <td>99</td>\n",
       "      <td>2024</td>\n",
       "      <td>9</td>\n",
       "      <td>59</td>\n",
       "      <td>47</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.406780</td>\n",
       "      <td>0.355932</td>\n",
       "      <td>0.101695</td>\n",
       "      <td>0.135593</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>24297</td>\n",
       "      <td>-0.351648</td>\n",
       "      <td>31</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2430</th>\n",
       "      <td>99</td>\n",
       "      <td>2024</td>\n",
       "      <td>10</td>\n",
       "      <td>73</td>\n",
       "      <td>65</td>\n",
       "      <td>8</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.424658</td>\n",
       "      <td>0.410959</td>\n",
       "      <td>0.068493</td>\n",
       "      <td>0.095890</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.840000e-16</td>\n",
       "      <td>24298</td>\n",
       "      <td>0.237288</td>\n",
       "      <td>31</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2431</th>\n",
       "      <td>99</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>56</td>\n",
       "      <td>47</td>\n",
       "      <td>9</td>\n",
       "      <td>26</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>24299</td>\n",
       "      <td>-0.232877</td>\n",
       "      <td>31</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2432</th>\n",
       "      <td>99</td>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>35</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>24300</td>\n",
       "      <td>-0.375000</td>\n",
       "      <td>31</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2433 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      location_id  Year  Month  crime_count  weekday  weekend  morning  \\\n",
       "0               1  2018      1           20       15        5        8   \n",
       "1               1  2018      2           20       18        2       11   \n",
       "2               1  2018      3           24       14       10       10   \n",
       "3               1  2018      4           27       17       10        8   \n",
       "4               1  2018      5           36       30        6       11   \n",
       "...           ...   ...    ...          ...      ...      ...      ...   \n",
       "2428           99  2024      8           91       70       21       33   \n",
       "2429           99  2024      9           59       47       12       24   \n",
       "2430           99  2024     10           73       65        8       31   \n",
       "2431           99  2024     11           56       47        9       26   \n",
       "2432           99  2024     12           35       31        4       18   \n",
       "\n",
       "      afternoon  evening  night  ...  morning_rate  afternoon_rate  \\\n",
       "0             6        4      2  ...      0.400000        0.300000   \n",
       "1             4        2      3  ...      0.550000        0.200000   \n",
       "2            12        2      0  ...      0.416667        0.500000   \n",
       "3            16        1      2  ...      0.296296        0.592593   \n",
       "4            11       10      4  ...      0.305556        0.305556   \n",
       "...         ...      ...    ...  ...           ...             ...   \n",
       "2428         46        8      4  ...      0.362637        0.505495   \n",
       "2429         21        6      8  ...      0.406780        0.355932   \n",
       "2430         30        5      7  ...      0.424658        0.410959   \n",
       "2431         20        4      6  ...      0.464286        0.357143   \n",
       "2432         11        3      3  ...      0.514286        0.314286   \n",
       "\n",
       "      evening_rate  night_rate  sin_month     cos_month  time_id  \\\n",
       "0         0.200000    0.100000   0.000000  1.000000e+00    24217   \n",
       "1         0.100000    0.150000   0.500000  8.660254e-01    24218   \n",
       "2         0.083333    0.000000   0.866025  5.000000e-01    24219   \n",
       "3         0.037037    0.074074   1.000000  6.123234e-17    24220   \n",
       "4         0.277778    0.111111   0.866025 -5.000000e-01    24221   \n",
       "...            ...         ...        ...           ...      ...   \n",
       "2428      0.087912    0.043956  -0.500000 -8.660254e-01    24296   \n",
       "2429      0.101695    0.135593  -0.866025 -5.000000e-01    24297   \n",
       "2430      0.068493    0.095890  -1.000000 -1.840000e-16    24298   \n",
       "2431      0.071429    0.107143  -0.866025  5.000000e-01    24299   \n",
       "2432      0.085714    0.085714  -0.500000  8.660254e-01    24300   \n",
       "\n",
       "      crime_pct_change  location_idx  time_idx  \n",
       "0            -0.166667             0         0  \n",
       "1             0.000000             0         1  \n",
       "2             0.200000             0         2  \n",
       "3             0.125000             0         3  \n",
       "4             0.333333             0         4  \n",
       "...                ...           ...       ...  \n",
       "2428          0.022472            31        79  \n",
       "2429         -0.351648            31        80  \n",
       "2430          0.237288            31        81  \n",
       "2431         -0.232877            31        82  \n",
       "2432         -0.375000            31        83  \n",
       "\n",
       "[2433 rows x 22 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_times = data[\"time_id\"].nunique()\n",
    "n_locations = data[\"location_id\"].nunique()\n",
    "location2idx = {location: i for i, location in enumerate(data[\"location_id\"].unique())}\n",
    "time2idx = {time: i for i, time in enumerate(data[\"time_id\"].unique())}\n",
    "data[\"location_idx\"] = data[\"location_id\"].map(location2idx)\n",
    "data[\"time_idx\"] = data[\"time_id\"].map(time2idx)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_size: 60\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">crime_count</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">cos_month</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location_idx</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>518.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>8.660254e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>6.123234e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.0</td>\n",
       "      <td>628.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>13.0</td>\n",
       "      <td>541.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>339.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>3.0</td>\n",
       "      <td>503.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>15.0</td>\n",
       "      <td>482.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.840000e-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.840000e-16</td>\n",
       "      <td>-1.840000e-16</td>\n",
       "      <td>-1.840000e-16</td>\n",
       "      <td>-1.840000e-16</td>\n",
       "      <td>-1.840000e-16</td>\n",
       "      <td>-1.840000e-16</td>\n",
       "      <td>-1.840000e-16</td>\n",
       "      <td>-1.840000e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>18.0</td>\n",
       "      <td>428.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>16.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>331.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>8.660254e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 384 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             crime_count                                                      \\\n",
       "location_idx          0      1     2     3     4      5      6     7      8    \n",
       "time_idx                                                                       \n",
       "0                   20.0  518.0  18.0  49.0  20.0  115.0  189.0   1.0  143.0   \n",
       "1                   20.0  504.0  29.0  58.0  16.0  108.0  179.0   1.0  139.0   \n",
       "2                   24.0  566.0  23.0  33.0  26.0  123.0  228.0   0.0  149.0   \n",
       "3                   27.0  563.0  26.0  40.0  20.0  118.0  246.0   0.0  170.0   \n",
       "4                   36.0  628.0  31.0  50.0  41.0  133.0  215.0   0.0  165.0   \n",
       "...                  ...    ...   ...   ...   ...    ...    ...   ...    ...   \n",
       "79                  13.0  541.0  34.0   5.0   9.0   83.0  226.0  51.0  339.0   \n",
       "80                   3.0  503.0  15.0  13.0  16.0   94.0  198.0  42.0  328.0   \n",
       "81                  15.0  482.0  17.0  12.0  12.0  108.0  209.0  39.0  360.0   \n",
       "82                  18.0  428.0  17.0  17.0  21.0   87.0  195.0  51.0  291.0   \n",
       "83                  16.0  431.0  20.0  14.0  13.0   60.0  198.0  24.0  331.0   \n",
       "\n",
       "                    ...     cos_month                                   \\\n",
       "location_idx    9   ...            22   23            24            25   \n",
       "time_idx            ...                                                  \n",
       "0             28.0  ...  0.000000e+00  0.0  1.000000e+00  1.000000e+00   \n",
       "1             21.0  ...  8.660254e-01  0.0  8.660254e-01  8.660254e-01   \n",
       "2             27.0  ...  5.000000e-01  0.0  5.000000e-01  5.000000e-01   \n",
       "3             34.0  ...  6.123234e-17  0.0  6.123234e-17  6.123234e-17   \n",
       "4             36.0  ... -5.000000e-01  0.0 -5.000000e-01 -5.000000e-01   \n",
       "...            ...  ...           ...  ...           ...           ...   \n",
       "79            20.0  ... -8.660254e-01  0.0 -8.660254e-01 -8.660254e-01   \n",
       "80            15.0  ... -5.000000e-01  0.0 -5.000000e-01 -5.000000e-01   \n",
       "81            21.0  ... -1.840000e-16  0.0 -1.840000e-16 -1.840000e-16   \n",
       "82            11.0  ...  0.000000e+00  0.0  5.000000e-01  5.000000e-01   \n",
       "83            15.0  ...  0.000000e+00  0.0  8.660254e-01  8.660254e-01   \n",
       "\n",
       "                                                                      \\\n",
       "location_idx            26            27            28            29   \n",
       "time_idx                                                               \n",
       "0             1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "1             8.660254e-01  8.660254e-01  8.660254e-01  8.660254e-01   \n",
       "2             5.000000e-01  5.000000e-01  5.000000e-01  5.000000e-01   \n",
       "3             6.123234e-17  6.123234e-17  6.123234e-17  6.123234e-17   \n",
       "4            -5.000000e-01 -5.000000e-01 -5.000000e-01 -5.000000e-01   \n",
       "...                    ...           ...           ...           ...   \n",
       "79           -8.660254e-01 -8.660254e-01 -8.660254e-01 -8.660254e-01   \n",
       "80           -5.000000e-01 -5.000000e-01 -5.000000e-01 -5.000000e-01   \n",
       "81           -1.840000e-16 -1.840000e-16 -1.840000e-16 -1.840000e-16   \n",
       "82            5.000000e-01  5.000000e-01  5.000000e-01  5.000000e-01   \n",
       "83            8.660254e-01  8.660254e-01  8.660254e-01  8.660254e-01   \n",
       "\n",
       "                                          \n",
       "location_idx            30            31  \n",
       "time_idx                                  \n",
       "0             1.000000e+00  1.000000e+00  \n",
       "1             8.660254e-01  8.660254e-01  \n",
       "2             5.000000e-01  5.000000e-01  \n",
       "3             6.123234e-17  6.123234e-17  \n",
       "4            -5.000000e-01 -5.000000e-01  \n",
       "...                    ...           ...  \n",
       "79           -8.660254e-01 -8.660254e-01  \n",
       "80           -5.000000e-01 -5.000000e-01  \n",
       "81           -1.840000e-16 -1.840000e-16  \n",
       "82            5.000000e-01  5.000000e-01  \n",
       "83            8.660254e-01  8.660254e-01  \n",
       "\n",
       "[84 rows x 384 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [\n",
    "    \"crime_count\",\n",
    "    \"crime_pct_change\",\n",
    "    \"Year\",\n",
    "    \"Month\",\n",
    "    \"morning_rate\",\n",
    "    \"evening_rate\",\n",
    "    \"afternoon_rate\",\n",
    "    \"night_rate\",\n",
    "    \"num_days\",\n",
    "    \"holiday_num\",\n",
    "    \"sin_month\",\n",
    "    \"cos_month\",\n",
    "]\n",
    "n_features = len(features)\n",
    "pivot_df = data.pivot(\n",
    "    index=\"time_idx\",\n",
    "    columns=\"location_idx\",\n",
    "    values=features,\n",
    ")\n",
    "pivot_df = pivot_df.fillna(0)\n",
    "train_size = int((len(pivot_df) - seq_len) - 12)\n",
    "print(f\"train_size: {train_size}\")\n",
    "# time_features = pd.DataFrame(index=pivot_df.index)\n",
    "# time_features[\"holiday_num\"] = data.groupby(\"time_idx\")[\"holiday_count\"].first()\n",
    "# time_features[\"sin_month\"] = data.groupby(\"time_idx\")[\"sin_month\"].first()\n",
    "# time_features[\"cos_month\"] = data.groupby(\"time_idx\")[\"cos_month\"].first()\n",
    "pivot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84, 384)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">crime_count</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">cos_month</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location_idx</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.552102</td>\n",
       "      <td>0.326531</td>\n",
       "      <td>0.836364</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.612613</td>\n",
       "      <td>0.546713</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.202247</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.464102</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.526508</td>\n",
       "      <td>0.551020</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.549550</td>\n",
       "      <td>0.512111</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.187266</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.933013</td>\n",
       "      <td>0.464102</td>\n",
       "      <td>0.933013</td>\n",
       "      <td>0.933013</td>\n",
       "      <td>0.933013</td>\n",
       "      <td>0.933013</td>\n",
       "      <td>0.933013</td>\n",
       "      <td>0.933013</td>\n",
       "      <td>0.933013</td>\n",
       "      <td>0.933013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.639854</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.684685</td>\n",
       "      <td>0.681661</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.224719</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.464102</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.634369</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.672727</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.639640</td>\n",
       "      <td>0.743945</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.303371</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.464102</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.753199</td>\n",
       "      <td>0.591837</td>\n",
       "      <td>0.854545</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.774775</td>\n",
       "      <td>0.636678</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.284644</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.464102</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.594150</td>\n",
       "      <td>0.653061</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>-0.027778</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.674740</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.936330</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066987</td>\n",
       "      <td>0.464102</td>\n",
       "      <td>0.066987</td>\n",
       "      <td>0.066987</td>\n",
       "      <td>0.066987</td>\n",
       "      <td>0.066987</td>\n",
       "      <td>0.066987</td>\n",
       "      <td>0.066987</td>\n",
       "      <td>0.066987</td>\n",
       "      <td>0.066987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.524680</td>\n",
       "      <td>0.265306</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.423423</td>\n",
       "      <td>0.577855</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.895131</td>\n",
       "      <td>0.309524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.464102</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.486289</td>\n",
       "      <td>0.306122</td>\n",
       "      <td>0.163636</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.549550</td>\n",
       "      <td>0.615917</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>1.014981</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.464102</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.485714</td>\n",
       "      <td>0.387569</td>\n",
       "      <td>0.306122</td>\n",
       "      <td>0.254545</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.360360</td>\n",
       "      <td>0.567474</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.756554</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.464102</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.393053</td>\n",
       "      <td>0.367347</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.117117</td>\n",
       "      <td>0.577855</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.906367</td>\n",
       "      <td>0.309524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.464102</td>\n",
       "      <td>0.933013</td>\n",
       "      <td>0.933013</td>\n",
       "      <td>0.933013</td>\n",
       "      <td>0.933013</td>\n",
       "      <td>0.933013</td>\n",
       "      <td>0.933013</td>\n",
       "      <td>0.933013</td>\n",
       "      <td>0.933013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 384 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             crime_count                                                    \\\n",
       "location_idx          0         1         2         3         4         5    \n",
       "time_idx                                                                     \n",
       "0               0.542857  0.552102  0.326531  0.836364  0.277778  0.612613   \n",
       "1               0.542857  0.526508  0.551020  1.000000  0.166667  0.549550   \n",
       "2               0.657143  0.639854  0.428571  0.545455  0.444444  0.684685   \n",
       "3               0.742857  0.634369  0.489796  0.672727  0.277778  0.639640   \n",
       "4               1.000000  0.753199  0.591837  0.854545  0.861111  0.774775   \n",
       "...                  ...       ...       ...       ...       ...       ...   \n",
       "79              0.342857  0.594150  0.653061  0.036364 -0.027778  0.324324   \n",
       "80              0.057143  0.524680  0.265306  0.181818  0.166667  0.423423   \n",
       "81              0.400000  0.486289  0.306122  0.163636  0.055556  0.549550   \n",
       "82              0.485714  0.387569  0.306122  0.254545  0.305556  0.360360   \n",
       "83              0.428571  0.393053  0.367347  0.200000  0.083333  0.117117   \n",
       "\n",
       "                                                      ... cos_month            \\\n",
       "location_idx        6         7         8         9   ...        22        23   \n",
       "time_idx                                              ...                       \n",
       "0             0.546713  0.016667  0.202247  0.619048  ...  0.500000  0.464102   \n",
       "1             0.512111  0.016667  0.187266  0.452381  ...  0.933013  0.464102   \n",
       "2             0.681661  0.000000  0.224719  0.595238  ...  0.750000  0.464102   \n",
       "3             0.743945  0.000000  0.303371  0.761905  ...  0.500000  0.464102   \n",
       "4             0.636678  0.000000  0.284644  0.809524  ...  0.250000  0.464102   \n",
       "...                ...       ...       ...       ...  ...       ...       ...   \n",
       "79            0.674740  0.850000  0.936330  0.428571  ...  0.066987  0.464102   \n",
       "80            0.577855  0.700000  0.895131  0.309524  ...  0.250000  0.464102   \n",
       "81            0.615917  0.650000  1.014981  0.452381  ...  0.500000  0.464102   \n",
       "82            0.567474  0.850000  0.756554  0.214286  ...  0.500000  0.464102   \n",
       "83            0.577855  0.400000  0.906367  0.309524  ...  0.500000  0.464102   \n",
       "\n",
       "                                                                          \\\n",
       "location_idx        24        25        26        27        28        29   \n",
       "time_idx                                                                   \n",
       "0             1.000000  1.000000  1.000000  1.000000  1.000000  1.000000   \n",
       "1             0.933013  0.933013  0.933013  0.933013  0.933013  0.933013   \n",
       "2             0.750000  0.750000  0.750000  0.750000  0.750000  0.750000   \n",
       "3             0.500000  0.500000  0.500000  0.500000  0.500000  0.500000   \n",
       "4             0.250000  0.250000  0.250000  0.250000  0.250000  0.250000   \n",
       "...                ...       ...       ...       ...       ...       ...   \n",
       "79            0.066987  0.066987  0.066987  0.066987  0.066987  0.066987   \n",
       "80            0.250000  0.250000  0.250000  0.250000  0.250000  0.250000   \n",
       "81            0.500000  0.500000  0.500000  0.500000  0.500000  0.500000   \n",
       "82            0.750000  0.750000  0.750000  0.750000  0.750000  0.750000   \n",
       "83            0.933013  0.933013  0.933013  0.933013  0.933013  0.933013   \n",
       "\n",
       "                                  \n",
       "location_idx        30        31  \n",
       "time_idx                          \n",
       "0             1.000000  1.000000  \n",
       "1             0.933013  0.933013  \n",
       "2             0.750000  0.750000  \n",
       "3             0.500000  0.500000  \n",
       "4             0.250000  0.250000  \n",
       "...                ...       ...  \n",
       "79            0.066987  0.066987  \n",
       "80            0.250000  0.250000  \n",
       "81            0.500000  0.500000  \n",
       "82            0.750000  0.750000  \n",
       "83            0.933013  0.933013  \n",
       "\n",
       "[84 rows x 384 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaled_df = pivot_df.copy()\n",
    "scaler = MinMaxScaler()\n",
    "print(scaled_df.shape)\n",
    "scaled_df[: train_size + seq_len] = scaler.fit_transform(\n",
    "    scaled_df[: train_size + seq_len]\n",
    ")\n",
    "scaled_df[train_size + seq_len :] = scaler.transform(scaled_df[train_size + seq_len :])\n",
    "scaled_df = pd.DataFrame(scaled_df, columns=pivot_df.columns)\n",
    "scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "def scale_by_feature_type(pivot_df, train_size, seq_len):\n",
    "    scaled_df = pivot_df.copy()\n",
    "    feature_types = pivot_df.columns.get_level_values(0).unique()\n",
    "    scaler_ls = []\n",
    "    for feature in feature_types:\n",
    "        feature_cols = [col for col in pivot_df.columns if col[0] == feature]\n",
    "        scaler = MinMaxScaler()\n",
    "        feature_data = pivot_df[feature_cols]\n",
    "        train_data = feature_data.iloc[: train_size + seq_len]\n",
    "        scaler.fit(train_data)\n",
    "        scaled_df[feature_cols] = scaler.transform(feature_data)\n",
    "        scaler_ls.append(scaler)\n",
    "    return scaled_df, scaler_ls\n",
    "\n",
    "\n",
    "scaled_df, scaler_ls = scale_by_feature_type(pivot_df, train_size, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_seq shape: (2304, 12, 12)\n",
      "y shape: (2304,)\n",
      "loc_idx shape: (2304,)\n",
      "time_idx shape: (2304,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def create_sequences(feat_df, seq_length=12):\n",
    "    X_seq = []\n",
    "    y_vals = []\n",
    "    loc_idx = []\n",
    "    time_idx = []\n",
    "    T = feat_df.shape[0]\n",
    "    locations = feat_df.columns.get_level_values(1).unique()\n",
    "    crime_feature = feat_df.columns.get_level_values(0)[\n",
    "        0\n",
    "    ]  # Assuming 'crime_count' is the first feature type\n",
    "    for location in locations:\n",
    "        location_data = feat_df.xs(location, axis=1, level=1)\n",
    "\n",
    "        # Create sliding windows\n",
    "        for i in range(T - seq_length):\n",
    "            # Extract feature window for all features\n",
    "            feature_window = location_data.iloc[\n",
    "                i : i + seq_length\n",
    "            ].values  # shape (seq_length, n_features)\n",
    "            y_val = feat_df[(crime_feature, location)].iloc[i + seq_length]\n",
    "            X_seq.append(feature_window)\n",
    "            y_vals.append(y_val)\n",
    "            loc_idx.append(location)\n",
    "            time_idx.append(i)\n",
    "    X_seq = np.array(X_seq)  # shape => (n_locations * n_times, seq_length, n_features)\n",
    "    y_vals = np.array(y_vals)  # shape => (n_locations * n_times,)\n",
    "    loc_idx = np.array(loc_idx)  # shape => (n_locations * n_times,)\n",
    "    time_idx = np.array(time_idx)  # shape => (n_locations * n_times,)\n",
    "    return X_seq, y_vals, loc_idx, time_idx\n",
    "\n",
    "\n",
    "seq_length = 12\n",
    "X_seq, y, loc_idx, time_idx = create_sequences(scaled_df, seq_length=seq_length)\n",
    "\n",
    "print(\"X_seq shape:\", X_seq.shape)  # (n_locations * n_times, seq_length, n_features)\n",
    "print(\"y shape:\", y.shape)  # (n_locations * n_times,)\n",
    "print(\"loc_idx shape:\", loc_idx.shape)  # (n_locations * n_times,)\n",
    "print(\"time_idx shape:\", time_idx.shape)  # (n_locations * n_times,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shapes: (1920, 12, 12) (1920,) (1920,) (1920,)\n",
      "Test shapes: (384, 12, 12) (384,) (384,) (384,)\n"
     ]
    }
   ],
   "source": [
    "train_mask = time_idx < train_size\n",
    "test_mask = time_idx >= train_size\n",
    "\n",
    "X_train = X_seq[train_mask]\n",
    "y_train = y[train_mask]\n",
    "loc_train = loc_idx[train_mask]\n",
    "time_train = time_idx[train_mask]\n",
    "\n",
    "X_test = X_seq[test_mask]\n",
    "y_test = y[test_mask]\n",
    "loc_test = loc_idx[test_mask]\n",
    "time_test = time_idx[test_mask]\n",
    "\n",
    "print(\"Train shapes:\", X_train.shape, y_train.shape, loc_train.shape, time_train.shape)\n",
    "print(\"Test shapes:\", X_test.shape, y_test.shape, loc_test.shape, time_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class CrimeDataset(Dataset):\n",
    "    def __init__(self, X, y, loc_idx, time_idx):\n",
    "        self.X = X  # n_sequences, seq_len, n_location\n",
    "        self.y = y  # n_sequences, n_location\n",
    "        self.loc_idx = loc_idx\n",
    "        self.time_idx = time_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = torch.tensor(self.X[idx], dtype=torch.float32)\n",
    "        y = torch.tensor(self.y[idx], dtype=torch.float32)\n",
    "        loc_idx = torch.tensor(self.loc_idx[idx], dtype=torch.long)\n",
    "        time_idx = torch.tensor(self.time_idx[idx], dtype=torch.long)\n",
    "        return X, y, loc_idx, time_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_size = n_features\n",
    "cat_size = n_locations\n",
    "batch_size = 32\n",
    "hidden_size = 128\n",
    "num_layers = 3\n",
    "embed_dim = 16\n",
    "output_size = 1\n",
    "num_epochs = 100\n",
    "dropout = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CrimeDataset(X_train, y_train, loc_train, time_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataset = CrimeDataset(X_test, y_test, loc_test, time_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_batch shape: torch.Size([32, 12, 12])\n",
      "y_batch shape: torch.Size([32])\n",
      "loc_batch shape: torch.Size([32])\n",
      "time_batch shape: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for X_batch, y_batch, loc_batch, time_batch in train_loader:\n",
    "    print(f\"X_batch shape: {X_batch.shape}\")\n",
    "    print(f\"y_batch shape: {y_batch.shape}\")\n",
    "    print(f\"loc_batch shape: {loc_batch.shape}\")\n",
    "    print(f\"time_batch shape: {time_batch.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrimeLSTM(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_size,\n",
    "        cat_size,\n",
    "        hidden_size,\n",
    "        embed_dim,\n",
    "        num_layers,\n",
    "        output_size,\n",
    "        dropout,\n",
    "    ):\n",
    "        super(CrimeLSTM, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(cat_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=num_size + embed_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.fc1 = nn.Linear(hidden_size, 64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(64, output_size)\n",
    "\n",
    "    def forward(self, X, loc, h_0, c_0):\n",
    "        \"\"\"\n",
    "        x: [batch_size, seq_len, n_feature]\n",
    "        h_0, c_0: [num_layers, batch_size, hidden_size]\n",
    "        output: [batch_size, n_location, output_size]\n",
    "        \"\"\"\n",
    "        _, seq_len, _ = X.shape\n",
    "        loc_embed = self.embedding(loc)\n",
    "        loc_embed = loc_embed.unsqueeze(1).repeat(1, seq_len, 1)\n",
    "        lstm_input = torch.cat((X, loc_embed), dim=2)\n",
    "        lstm_output, (h_n, c_n) = self.lstm(lstm_input, (h_0, c_0))\n",
    "        last_output = lstm_output[:, -1, :]\n",
    "        fc_out = self.fc1(last_output)\n",
    "        fc_out = self.relu(fc_out)\n",
    "        fc_out = self.dropout(fc_out)\n",
    "        fc_out = self.fc2(fc_out)  # [batch_size*n_location, output_size]\n",
    "        return fc_out, (h_n, c_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrimeLSTM(\n",
      "  (embedding): Embedding(32, 16)\n",
      "  (lstm): LSTM(28, 128, num_layers=3, batch_first=True)\n",
      "  (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = CrimeLSTM(\n",
    "    num_size, cat_size, hidden_size, embed_dim, num_layers, output_size, dropout\n",
    ").to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define loss function and optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation\n",
    "def evaluate_model(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    num_batches = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch, loc_batch, _ in test_loader:\n",
    "            X_batch, y_batch, loc_batch = (\n",
    "                X_batch.to(device),\n",
    "                y_batch.to(device),\n",
    "                loc_batch.to(device),\n",
    "            )\n",
    "            curr_batch_size = X_batch.shape[0]\n",
    "            h = torch.zeros(num_layers, curr_batch_size, hidden_size).to(device)\n",
    "            c = torch.zeros(num_layers, curr_batch_size, hidden_size).to(device)\n",
    "            score, (_, _) = model(X_batch, loc_batch, h, c)\n",
    "            score = score.view(curr_batch_size)\n",
    "            loss = criterion(score, y_batch)\n",
    "            val_loss += loss.item()\n",
    "            num_batches += 1\n",
    "    total_val_loss = val_loss / num_batches\n",
    "    return total_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in best_lstm_model.pth with validation loss: 0.640772140430\n",
      "Epoch [1/100], Train Loss: 0.066976617463, Val Loss: 0.640772140430, LR: 0.001000000000\n",
      "Model saved in best_lstm_model.pth with validation loss: 0.617640978113\n",
      "Epoch [2/100], Train Loss: 0.047269494242, Val Loss: 0.617640978113, LR: 0.001000000000\n",
      "Model saved in best_lstm_model.pth with validation loss: 0.580271906452\n",
      "Epoch [3/100], Train Loss: 0.046116039623, Val Loss: 0.580271906452, LR: 0.001000000000\n",
      "Model saved in best_lstm_model.pth with validation loss: 0.562619347824\n",
      "Epoch [4/100], Train Loss: 0.038433042075, Val Loss: 0.562619347824, LR: 0.001000000000\n",
      "Model saved in best_lstm_model.pth with validation loss: 0.528032751288\n",
      "Epoch [5/100], Train Loss: 0.036915855110, Val Loss: 0.528032751288, LR: 0.001000000000\n",
      "Model saved in best_lstm_model.pth with validation loss: 0.527905205498\n",
      "Epoch [6/100], Train Loss: 0.033245160275, Val Loss: 0.527905205498, LR: 0.001000000000\n",
      "Model saved in best_lstm_model.pth with validation loss: 0.501884289823\n",
      "Epoch [7/100], Train Loss: 0.032911769239, Val Loss: 0.501884289823, LR: 0.001000000000\n",
      "Model saved in best_lstm_model.pth with validation loss: 0.476573048742\n",
      "Epoch [8/100], Train Loss: 0.030450754302, Val Loss: 0.476573048742, LR: 0.001000000000\n",
      "Model saved in best_lstm_model.pth with validation loss: 0.471901221589\n",
      "Epoch [9/100], Train Loss: 0.029356457402, Val Loss: 0.471901221589, LR: 0.001000000000\n",
      "Epoch [10/100], Train Loss: 0.029426277010, Val Loss: 0.475589198060, LR: 0.001000000000\n",
      "Model saved in best_lstm_model.pth with validation loss: 0.458682603707\n",
      "Epoch [11/100], Train Loss: 0.028507218556, Val Loss: 0.458682603707, LR: 0.001000000000\n",
      "Epoch [12/100], Train Loss: 0.029253917312, Val Loss: 0.464049131299, LR: 0.001000000000\n",
      "Model saved in best_lstm_model.pth with validation loss: 0.451073966067\n",
      "Epoch [13/100], Train Loss: 0.027107639099, Val Loss: 0.451073966067, LR: 0.001000000000\n",
      "Epoch [14/100], Train Loss: 0.027609942465, Val Loss: 0.473884160553, LR: 0.001000000000\n",
      "Epoch [15/100], Train Loss: 0.026917376354, Val Loss: 0.474013128590, LR: 0.001000000000\n",
      "Epoch [16/100], Train Loss: 0.026653239162, Val Loss: 0.476486237797, LR: 0.001000000000\n",
      "Epoch [17/100], Train Loss: 0.026652684280, Val Loss: 0.478879382407, LR: 0.001000000000\n",
      "Epoch [18/100], Train Loss: 0.026569544446, Val Loss: 0.478086510596, LR: 0.001000000000\n",
      "Epoch [19/100], Train Loss: 0.026104473416, Val Loss: 0.495778824436, LR: 0.000500000000\n",
      "Epoch [20/100], Train Loss: 0.026006646563, Val Loss: 0.474123633699, LR: 0.000500000000\n",
      "Epoch [21/100], Train Loss: 0.025278140418, Val Loss: 0.484635781497, LR: 0.000500000000\n",
      "Epoch [22/100], Train Loss: 0.024110546072, Val Loss: 0.472680601214, LR: 0.000500000000\n",
      "Epoch [23/100], Train Loss: 0.023753185679, Val Loss: 0.468438262624, LR: 0.000500000000\n",
      "Epoch [24/100], Train Loss: 0.024879146802, Val Loss: 0.487028028777, LR: 0.000500000000\n",
      "Epoch [25/100], Train Loss: 0.024597615966, Val Loss: 0.465540343585, LR: 0.000250000000\n",
      "Epoch [26/100], Train Loss: 0.024221683651, Val Loss: 0.484215687223, LR: 0.000250000000\n",
      "Epoch [27/100], Train Loss: 0.023638509819, Val Loss: 0.481158808301, LR: 0.000250000000\n",
      "Epoch [28/100], Train Loss: 0.023160229422, Val Loss: 0.482272365751, LR: 0.000250000000\n",
      "Epoch [29/100], Train Loss: 0.023512224248, Val Loss: 0.480892695603, LR: 0.000250000000\n",
      "Epoch [30/100], Train Loss: 0.023420557395, Val Loss: 0.476744922576, LR: 0.000250000000\n",
      "Epoch [31/100], Train Loss: 0.023962263406, Val Loss: 0.486053761522, LR: 0.000125000000\n",
      "Epoch [32/100], Train Loss: 0.023340358663, Val Loss: 0.481110050576, LR: 0.000125000000\n",
      "Epoch [33/100], Train Loss: 0.022653644563, Val Loss: 0.479976674697, LR: 0.000125000000\n",
      "Epoch [34/100], Train Loss: 0.023006152470, Val Loss: 0.480060743595, LR: 0.000125000000\n",
      "Epoch [35/100], Train Loss: 0.022894580010, Val Loss: 0.480509360243, LR: 0.000125000000\n",
      "Epoch [36/100], Train Loss: 0.023067019212, Val Loss: 0.479500768706, LR: 0.000125000000\n",
      "Epoch [37/100], Train Loss: 0.023249082112, Val Loss: 0.478488142098, LR: 0.000062500000\n",
      "Epoch [38/100], Train Loss: 0.022867198382, Val Loss: 0.480810852915, LR: 0.000062500000\n",
      "Epoch [39/100], Train Loss: 0.023011142683, Val Loss: 0.478812110727, LR: 0.000062500000\n",
      "Epoch [40/100], Train Loss: 0.023039256238, Val Loss: 0.478647217038, LR: 0.000062500000\n",
      "Epoch [41/100], Train Loss: 0.023231656663, Val Loss: 0.480847156257, LR: 0.000062500000\n",
      "Epoch [42/100], Train Loss: 0.022652842198, Val Loss: 0.480249696838, LR: 0.000062500000\n",
      "Epoch [43/100], Train Loss: 0.022950081481, Val Loss: 0.480670469580, LR: 0.000031250000\n",
      "Epoch [44/100], Train Loss: 0.022592460302, Val Loss: 0.478907230388, LR: 0.000031250000\n",
      "Epoch [45/100], Train Loss: 0.021947136987, Val Loss: 0.480024678012, LR: 0.000031250000\n",
      "Epoch [46/100], Train Loss: 0.022672112798, Val Loss: 0.478429992218, LR: 0.000031250000\n",
      "Epoch [47/100], Train Loss: 0.022656249814, Val Loss: 0.479283438452, LR: 0.000031250000\n",
      "Epoch [48/100], Train Loss: 0.022505553106, Val Loss: 0.478880767284, LR: 0.000031250000\n",
      "Epoch [49/100], Train Loss: 0.022243532601, Val Loss: 0.479892573319, LR: 0.000015625000\n",
      "Epoch [50/100], Train Loss: 0.022850400225, Val Loss: 0.479433816935, LR: 0.000015625000\n",
      "Epoch [51/100], Train Loss: 0.022181370948, Val Loss: 0.479585444865, LR: 0.000015625000\n",
      "Epoch [52/100], Train Loss: 0.022417390967, Val Loss: 0.479513099534, LR: 0.000015625000\n",
      "Epoch [53/100], Train Loss: 0.021725592576, Val Loss: 0.479520622796, LR: 0.000015625000\n",
      "Epoch [54/100], Train Loss: 0.022333422583, Val Loss: 0.479599684671, LR: 0.000015625000\n",
      "Epoch [55/100], Train Loss: 0.022670381307, Val Loss: 0.480171502063, LR: 0.000007812500\n",
      "Epoch [56/100], Train Loss: 0.021760979341, Val Loss: 0.480109002868, LR: 0.000007812500\n",
      "Epoch [57/100], Train Loss: 0.022310786562, Val Loss: 0.479414762153, LR: 0.000007812500\n",
      "Epoch [58/100], Train Loss: 0.022123143023, Val Loss: 0.479635157118, LR: 0.000007812500\n",
      "Epoch [59/100], Train Loss: 0.022253961302, Val Loss: 0.480309663729, LR: 0.000007812500\n",
      "Epoch [60/100], Train Loss: 0.022879389231, Val Loss: 0.479830367879, LR: 0.000007812500\n",
      "Epoch [61/100], Train Loss: 0.022500405383, Val Loss: 0.479686358866, LR: 0.000003906250\n",
      "Epoch [62/100], Train Loss: 0.021888992718, Val Loss: 0.479836426093, LR: 0.000003906250\n",
      "Epoch [63/100], Train Loss: 0.022141024362, Val Loss: 0.479560211262, LR: 0.000003906250\n",
      "Epoch [64/100], Train Loss: 0.022111272346, Val Loss: 0.479568780943, LR: 0.000003906250\n",
      "Epoch [65/100], Train Loss: 0.021705829880, Val Loss: 0.479672729775, LR: 0.000003906250\n",
      "Epoch [66/100], Train Loss: 0.022476522702, Val Loss: 0.479489466253, LR: 0.000003906250\n",
      "Epoch [67/100], Train Loss: 0.022632121667, Val Loss: 0.479716774425, LR: 0.000001953125\n",
      "Epoch [68/100], Train Loss: 0.022401878362, Val Loss: 0.479813381719, LR: 0.000001953125\n",
      "Epoch [69/100], Train Loss: 0.022443692309, Val Loss: 0.479758668109, LR: 0.000001953125\n",
      "Epoch [70/100], Train Loss: 0.022264340737, Val Loss: 0.479601913326, LR: 0.000001953125\n",
      "Epoch [71/100], Train Loss: 0.022342293694, Val Loss: 0.479506990989, LR: 0.000001953125\n",
      "Epoch [72/100], Train Loss: 0.022306882117, Val Loss: 0.479464723418, LR: 0.000001953125\n",
      "Epoch [73/100], Train Loss: 0.022041806222, Val Loss: 0.479334426966, LR: 0.000001000000\n",
      "Epoch [74/100], Train Loss: 0.022042595176, Val Loss: 0.479295845454, LR: 0.000001000000\n",
      "Epoch [75/100], Train Loss: 0.022209399046, Val Loss: 0.479366891047, LR: 0.000001000000\n",
      "Epoch [76/100], Train Loss: 0.022119192701, Val Loss: 0.479315478199, LR: 0.000001000000\n",
      "Epoch [77/100], Train Loss: 0.022567146908, Val Loss: 0.479407131555, LR: 0.000001000000\n",
      "Epoch [78/100], Train Loss: 0.022230908104, Val Loss: 0.479478912506, LR: 0.000001000000\n",
      "Epoch [79/100], Train Loss: 0.022218643905, Val Loss: 0.479662338776, LR: 0.000001000000\n",
      "Epoch [80/100], Train Loss: 0.022238203169, Val Loss: 0.479662737266, LR: 0.000001000000\n",
      "Epoch [81/100], Train Loss: 0.022419865957, Val Loss: 0.479644698207, LR: 0.000001000000\n",
      "Epoch [82/100], Train Loss: 0.022170844597, Val Loss: 0.479747823828, LR: 0.000001000000\n",
      "Epoch [83/100], Train Loss: 0.022614880799, Val Loss: 0.479763347772, LR: 0.000001000000\n",
      "Epoch [84/100], Train Loss: 0.022679718351, Val Loss: 0.479774835131, LR: 0.000001000000\n",
      "Epoch [85/100], Train Loss: 0.021848031366, Val Loss: 0.479791072391, LR: 0.000001000000\n",
      "Epoch [86/100], Train Loss: 0.022458219466, Val Loss: 0.479770659702, LR: 0.000001000000\n",
      "Epoch [87/100], Train Loss: 0.022580089513, Val Loss: 0.479781762542, LR: 0.000001000000\n",
      "Epoch [88/100], Train Loss: 0.021547615885, Val Loss: 0.479716896623, LR: 0.000001000000\n",
      "Epoch [89/100], Train Loss: 0.022197279598, Val Loss: 0.479714692687, LR: 0.000001000000\n",
      "Epoch [90/100], Train Loss: 0.022410018300, Val Loss: 0.479821906619, LR: 0.000001000000\n",
      "Epoch [91/100], Train Loss: 0.022069694769, Val Loss: 0.479852811317, LR: 0.000001000000\n",
      "Epoch [92/100], Train Loss: 0.022033538499, Val Loss: 0.479822588541, LR: 0.000001000000\n",
      "Epoch [93/100], Train Loss: 0.022042686741, Val Loss: 0.479764878827, LR: 0.000001000000\n",
      "Epoch [94/100], Train Loss: 0.022052287761, Val Loss: 0.479912281735, LR: 0.000001000000\n",
      "Epoch [95/100], Train Loss: 0.023064867298, Val Loss: 0.479878239178, LR: 0.000001000000\n",
      "Epoch [96/100], Train Loss: 0.021917012660, Val Loss: 0.479806375612, LR: 0.000001000000\n",
      "Epoch [97/100], Train Loss: 0.022431409856, Val Loss: 0.479874605973, LR: 0.000001000000\n",
      "Epoch [98/100], Train Loss: 0.022410478893, Val Loss: 0.479967245599, LR: 0.000001000000\n",
      "Epoch [99/100], Train Loss: 0.021882305030, Val Loss: 0.479992865352, LR: 0.000001000000\n",
      "Epoch [100/100], Train Loss: 0.022224042658, Val Loss: 0.479927051968, LR: 0.000001000000\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode=\"min\",  # because we're monitoring loss\n",
    "    factor=0.5,  # how much to reduce the LR\n",
    "    patience=5,  # how many epochs to wait\n",
    "    threshold=1e-4,  # min improvement to be considered\n",
    "    cooldown=0,  # cooldown after reduction\n",
    "    min_lr=1e-6,  # don’t go below this\n",
    ")\n",
    "best_val_loss = float(\"inf\")\n",
    "best_model_path = \"best_lstm_model.pth\"\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    num_batches = 0\n",
    "    for X_batch, y_batch, loc_batch, _ in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        curr_batch_size = X_batch.shape[0]\n",
    "        X_batch, y_batch, loc_batch = (\n",
    "            X_batch.to(device),\n",
    "            y_batch.to(device),\n",
    "            loc_batch.to(device),\n",
    "        )\n",
    "        h = torch.zeros(num_layers, curr_batch_size, hidden_size).to(device)\n",
    "        c = torch.zeros(num_layers, curr_batch_size, hidden_size).to(device)\n",
    "        score, (_, _) = model(X_batch, loc_batch, h, c)\n",
    "        score = score.reshape(curr_batch_size)\n",
    "        loss = criterion(score, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        num_batches += 1\n",
    "    train_loss /= num_batches\n",
    "    train_losses.append(train_loss)\n",
    "    val_loss = evaluate_model(model, test_loader, criterion)\n",
    "    val_losses.append(val_loss)\n",
    "    scheduler.step(val_loss)\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"Model saved in {best_model_path} with validation loss: {val_loss:.12f}\")\n",
    "    print(\n",
    "        f\"Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss:.12f}, Val Loss: {val_loss:.12f}, LR: {scheduler.get_last_lr()[0]:.12f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot training and validation loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label=\"Training Loss\")\n",
    "plt.plot(val_losses, label=\"Validation Loss\")\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"training_validation_loss.pdf\", format=\"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #####################  test set  #####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrimeLSTM(\n",
       "  (embedding): Embedding(32, 16)\n",
       "  (lstm): LSTM(28, 128, num_layers=3, batch_first=True)\n",
       "  (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CrimeLSTM(num_size, cat_size, hidden_size, embed_dim, num_layers, output_size, dropout)\n",
    "model.load_state_dict(torch.load('best_lstm_model.pth', map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_size: 48\n",
      "(72, 372)\n",
      "X_seq shape: (1860, 12, 12)\n",
      "y shape: (1860,)\n",
      "loc_idx shape: (1860,)\n",
      "time_idx shape: (1860,)\n",
      "Test shapes: (1860, 12, 12) (1860,) (1860,) (1860,)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"rnn_data_test.csv\")\n",
    "seq_len = 12\n",
    "n_times = data[\"time_id\"].nunique()\n",
    "n_locations = data[\"location_id\"].nunique()\n",
    "location2idx = {location: i for i, location in enumerate(data[\"location_id\"].unique())}\n",
    "time2idx = {time: i for i, time in enumerate(data[\"time_id\"].unique())}\n",
    "data[\"location_idx\"] = data[\"location_id\"].map(location2idx)\n",
    "data[\"time_idx\"] = data[\"time_id\"].map(time2idx)\n",
    "\n",
    "features = [\n",
    "    \"crime_count\",\n",
    "    \"crime_pct_change\",\n",
    "    \"Year\",\n",
    "    \"Month\",\n",
    "    \"morning_rate\",\n",
    "    \"evening_rate\",\n",
    "    \"afternoon_rate\",\n",
    "    \"night_rate\",\n",
    "    \"num_days\",\n",
    "    \"holiday_num\",\n",
    "    \"sin_month\",\n",
    "    \"cos_month\",\n",
    "]\n",
    "n_features = len(features)\n",
    "pivot_df = data.pivot(\n",
    "    index=\"time_idx\",\n",
    "    columns=\"location_idx\",\n",
    "    values=features,\n",
    ")\n",
    "pivot_df = pivot_df.fillna(0)\n",
    "train_size = int((len(pivot_df) - seq_len) - 12)\n",
    "print(f\"train_size: {train_size}\")\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaled_df = pivot_df.copy()\n",
    "scaler = MinMaxScaler()\n",
    "print(scaled_df.shape)\n",
    "scaled_df[: train_size + seq_len] = scaler.fit_transform(\n",
    "    scaled_df[: train_size + seq_len]\n",
    ")\n",
    "scaled_df[train_size + seq_len :] = scaler.transform(scaled_df[train_size + seq_len :])\n",
    "scaled_df = pd.DataFrame(scaled_df, columns=pivot_df.columns)\n",
    "scaled_df\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def scale_by_feature_type(pivot_df, train_size, seq_len):\n",
    "    scaled_df = pivot_df.copy()\n",
    "    feature_types = pivot_df.columns.get_level_values(0).unique()\n",
    "    scaler_ls = []\n",
    "    for feature in feature_types:\n",
    "        feature_cols = [col for col in pivot_df.columns if col[0] == feature]\n",
    "        scaler = MinMaxScaler()\n",
    "        feature_data = pivot_df[feature_cols]\n",
    "        train_data = feature_data.iloc[: train_size + seq_len]\n",
    "        scaler.fit(train_data)\n",
    "        scaled_df[feature_cols] = scaler.transform(feature_data)\n",
    "        scaler_ls.append(scaler)\n",
    "    return scaled_df, scaler_ls\n",
    "\n",
    "scaled_df, scaler_ls = scale_by_feature_type(pivot_df, train_size, seq_len)\n",
    "\n",
    "\n",
    "def create_sequences(feat_df, seq_length=12):\n",
    "    X_seq = []\n",
    "    y_vals = []\n",
    "    loc_idx = []\n",
    "    time_idx = []\n",
    "    T = feat_df.shape[0]\n",
    "    locations = feat_df.columns.get_level_values(1).unique()\n",
    "    crime_feature = feat_df.columns.get_level_values(0)[\n",
    "        0\n",
    "    ] \n",
    "    for location in locations:\n",
    "        location_data = feat_df.xs(location, axis=1, level=1)\n",
    "\n",
    "        for i in range(T - seq_length):\n",
    "            feature_window = location_data.iloc[\n",
    "                i : i + seq_length\n",
    "            ].values  # shape (seq_length, n_features)\n",
    "            y_val = feat_df[(crime_feature, location)].iloc[i + seq_length]\n",
    "            X_seq.append(feature_window)\n",
    "            y_vals.append(y_val)\n",
    "            loc_idx.append(location)\n",
    "            time_idx.append(i)\n",
    "    X_seq = np.array(X_seq)  # shape => (n_locations * n_times, seq_length, n_features)\n",
    "    y_vals = np.array(y_vals)  # shape => (n_locations * n_times,)\n",
    "    loc_idx = np.array(loc_idx)  # shape => (n_locations * n_times,)\n",
    "    time_idx = np.array(time_idx)  # shape => (n_locations * n_times,)\n",
    "    return X_seq, y_vals, loc_idx, time_idx\n",
    "\n",
    "\n",
    "seq_length = 12\n",
    "X_seq, y, loc_idx, time_idx = create_sequences(scaled_df, seq_length=seq_length)\n",
    "\n",
    "print(\"X_seq shape:\", X_seq.shape)  # (n_locations * n_times, seq_length, n_features)\n",
    "print(\"y shape:\", y.shape)  # (n_locations * n_times,)\n",
    "print(\"loc_idx shape:\", loc_idx.shape)  # (n_locations * n_times,)\n",
    "print(\"time_idx shape:\", time_idx.shape)  # (n_locations * n_times,)\n",
    "\n",
    "train_mask = time_idx < train_size\n",
    "test_mask = time_idx >= train_size\n",
    "\n",
    "X_test = X_seq\n",
    "y_test = y\n",
    "loc_test = loc_idx\n",
    "time_test = time_idx\n",
    "\n",
    "print(\"Test shapes:\", X_test.shape, y_test.shape, loc_test.shape, time_test.shape)\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class CrimeDataset(Dataset):\n",
    "    def __init__(self, X, y, loc_idx, time_idx):\n",
    "        self.X = X  # n_sequences, seq_len, n_location\n",
    "        self.y = y  # n_sequences, n_location\n",
    "        self.loc_idx = loc_idx\n",
    "        self.time_idx = time_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = torch.tensor(self.X[idx], dtype=torch.float32)\n",
    "        y = torch.tensor(self.y[idx], dtype=torch.float32)\n",
    "        loc_idx = torch.tensor(self.loc_idx[idx], dtype=torch.long)\n",
    "        time_idx = torch.tensor(self.time_idx[idx], dtype=torch.long)\n",
    "        return X, y, loc_idx, time_idx\n",
    "    \n",
    "num_size = n_features\n",
    "cat_size = n_locations\n",
    "batch_size = 32\n",
    "hidden_size = 128\n",
    "num_layers = 3\n",
    "embed_dim = 16\n",
    "output_size = 1\n",
    "num_epochs = 100\n",
    "dropout = 0.5\n",
    "\n",
    "test_dataset = CrimeDataset(X_test, y_test, loc_test, time_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions(model, test_loader, n_locations, device, num_layers, hidden_size):\n",
    "    result = np.zeros(\n",
    "        (\n",
    "            len(test_loader.dataset) // n_locations,\n",
    "            n_locations,\n",
    "            2,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    def get_result(result, loader):\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, (X_batch, y_batch, loc_batch, time_batch) in enumerate(loader):\n",
    "                curr_batch_size = X_batch.shape[0]\n",
    "                X_batch, y_batch, loc_batch = (\n",
    "                    X_batch.to(device),\n",
    "                    y_batch.to(device),\n",
    "                    loc_batch.to(device),\n",
    "                )\n",
    "                h = torch.zeros(num_layers, curr_batch_size, hidden_size).to(device)\n",
    "                c = torch.zeros(num_layers, curr_batch_size, hidden_size).to(device)\n",
    "                score, (_, _) = model(X_batch, loc_batch, h, c)\n",
    "                score = score.reshape(curr_batch_size)\n",
    "                result[time_batch, loc_batch.cpu().numpy(), 0] = score.cpu().numpy()\n",
    "                result[time_batch, loc_batch.cpu().numpy(), 1] = y_batch.cpu().numpy()\n",
    "\n",
    "    get_result(result, test_loader)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = predictions(model, test_loader, n_locations, device, num_layers, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_unscaled = np.zeros(result.shape)\n",
    "result_unscaled[:, :, 0] = scaler_ls[0].inverse_transform(result[:, :, 0])\n",
    "result_unscaled[:, :, 1] = scaler_ls[0].inverse_transform(result[:, :, 1])\n",
    "result_unscaled = np.round(result_unscaled).astype(int)\n",
    "\n",
    "result_df = data.copy()\n",
    "result_df[\"lstm_pred\"] = np.nan\n",
    "for i in range(len(result_unscaled)):\n",
    "    for j in range(len(result_unscaled[i])):\n",
    "        result_df.loc[\n",
    "            (result_df[\"time_idx\"] == i + seq_length)\n",
    "            & (result_df[\"location_idx\"] == j),\n",
    "            \"lstm_pred\",\n",
    "        ] = result_unscaled[i, j, 0]\n",
    "\n",
    "result_df = result_df[result_df[\"time_idx\"] > seq_length - 1]\n",
    "result_df.to_csv(\"lstm_predictions.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
