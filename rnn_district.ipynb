{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import torch\n", "import torch.nn as nn\n", "import numpy as np\n", "import pandas as pd\n", "import matplotlib.pyplot as plt\n", "from sklearn.preprocessing import MinMaxScaler\n", "import time"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Set random seed for reproducibility"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["torch.manual_seed(42)\n", "np.random.seed(42)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Device configuration"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["device = \"mps\"\n", "print(f\"Using device: {device}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Load and prepare data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data = pd.read_csv(\"./data/rnn_full_data.csv\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Create a unique location identifier and time key"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data[\"location_id\"] = (\n", "    data[\"Location Group\"].astype(str) + \"_\" + data[\"District\"].astype(str)\n", ")\n", "data[\"time_key\"] = data[\"Year\"] * 12 + data[\"Month\"]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Get unique locations and time points"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["locations = data[\"location_id\"].unique()\n", "time_points = sorted(data[\"time_key\"].unique())"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(f\"Number of unique locations: {len(locations)}\")\n", "print(f\"Number of time points: {len(time_points)}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Create a dictionary mapping location to index for faster lookup"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["loc_to_idx = {loc: idx for idx, loc in enumerate(locations)}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Create a matrix where rows=time, columns=locations"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["crime_matrix = np.zeros((len(time_points), len(locations)))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Fill the matrix with crime counts"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for _, row in data.iterrows():\n", "    time_idx = list(time_points).index(row[\"time_key\"])\n", "    loc_idx = loc_to_idx[row[\"location_id\"]]\n", "    crime_matrix[time_idx, loc_idx] = row[\"crime_count\"]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Normalize data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["scaler = MinMaxScaler()\n", "crime_matrix_scaled = scaler.fit_transform(crime_matrix)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Set sequence length (use 12 months to predict the next month)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["seq_length = 12"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In this approach:<br>\n", "- Each time step is processed one at a time (no batching of sequences)<br>\n", "- All locations are processed simultaneously (as if they're a \"batch\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["This means we need the data shaped as:<br>\n", "[number of sequences, sequence_length, number of locations]<br>\n", "where each sequence is a sliding window of 12 months"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def create_sequences(data, seq_length):\n", "    \"\"\"\n", "    Create sequences from the time series data without batching.\n", "    Each sequence will contain all locations.\n", "    \"\"\"\n", "    sequences = []\n", "    targets = []\n", "    for i in range(len(data) - seq_length):\n", "        # Extract sequence of length seq_length\n", "        seq = data[i : i + seq_length]\n", "        # Target is the next time step after the sequence\n", "        target = data[i + seq_length]\n", "        sequences.append(seq)\n", "        targets.append(target)\n", "    return np.array(sequences), np.array(targets)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Create sequences"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X, y = create_sequences(crime_matrix_scaled, seq_length)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(f\"Number of sequences: {len(X)}\")\n", "print(f\"Input shape: {X.shape}\")  # [n_sequences, seq_length, n_locations]\n", "print(f\"Target shape: {y.shape}\")  # [n_sequences, n_locations]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Split data into train and validation sets (80% train, 20% validation)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_size = int(0.8 * len(X))\n", "X_train, X_val = X[:train_size], X[train_size:]\n", "y_train, y_val = y[:train_size], y[train_size:]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(f\"Training sequences: {len(X_train)}\")\n", "print(f\"Validation sequences: {len(X_val)}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Convert to PyTorch tensors"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train_tensor = torch.FloatTensor(X_train).to(device)\n", "y_train_tensor = torch.FloatTensor(y_train).to(device)\n", "X_val_tensor = torch.FloatTensor(X_val).to(device)\n", "y_val_tensor = torch.FloatTensor(y_val).to(device)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Define the RNN model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class CrimeRNN(nn.Module):\n", "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n", "        super(CrimeRNN, self).__init__()\n", "        self.hidden_size = hidden_size\n", "        self.num_layers = num_layers\n\n", "        # Define the GRU layer\n", "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n\n", "        # Define the output layer\n", "        self.fc = nn.Linear(hidden_size, output_size)\n", "    def forward(self, x, h=None):\n", "        # Initialize hidden state if not provided\n", "        if h is None:\n", "            h = torch.zeros(self.num_layers, 1, self.hidden_size).to(device)\n", "        else:\n", "            # Detach the hidden state to prevent backpropagation through the entire history\n", "            h = h.detach()\n\n", "        # Forward propagate the GRU\n", "        # Input shape: [1, seq_length, n_locations]\n", "        # Output shape: [1, seq_length, hidden_size]\n", "        out, h = self.gru(x.unsqueeze(0), h)\n\n", "        # Decode the hidden state of the last time step\n", "        # out[:, -1, :] shape: [1, hidden_size]\n", "        # Output shape after linear layer: [1, n_locations]\n", "        out = self.fc(out[:, -1, :])\n", "        return out.squeeze(0), h"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Initialize model parameters"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["input_size = len(locations)  # Number of locations\n", "hidden_size = 32\n", "num_layers = 2\n", "output_size = len(locations)  # Predicting crime count for all locations"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Initialize the model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model = CrimeRNN(input_size, hidden_size, num_layers, output_size).to(device)\n", "print(model)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Define loss function and optimizer"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["criterion = nn.MSELoss()\n", "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Training function"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def train_model(\n", "    model, X_train, y_train, X_val, y_val, criterion, optimizer, num_epochs=50\n", "):\n", "    train_losses = []\n", "    val_losses = []\n", "    start_time = time.time()\n\n", "    # No batches - process each sequence individually\n", "    for epoch in range(num_epochs):\n", "        model.train()\n", "        train_loss = 0\n", "        h = None  # Reset hidden state at the start of each epoch\n\n", "        # Process each sequence (no batching)\n", "        for i in range(len(X_train)):\n", "            # Get a single sequence with all locations\n", "            sequence = X_train[i]\n", "            target = y_train[i]\n\n", "            # Forward pass\n", "            output, h = model(sequence, h)\n", "            loss = criterion(output, target)\n\n", "            # Backward and optimize\n", "            optimizer.zero_grad()\n", "            loss.backward()\n", "            optimizer.step()\n", "            train_loss += loss.item()\n\n", "        # Validation\n", "        model.eval()\n", "        val_loss = 0\n", "        with torch.no_grad():\n", "            h = None  # Reset hidden state for validation\n", "            for i in range(len(X_val)):\n", "                output, h = model(X_val[i], h)\n", "                loss = criterion(output, y_val[i])\n", "                val_loss += loss.item()\n\n", "        # Calculate average losses\n", "        train_loss /= len(X_train)\n", "        val_loss /= len(X_val)\n", "        train_losses.append(train_loss)\n", "        val_losses.append(val_loss)\n\n", "        # Print progress\n", "        if (epoch + 1) % 5 == 0:\n", "            elapsed = time.time() - start_time\n", "            print(\n", "                f\"Epoch [{epoch+1}/{num_epochs}], \"\n", "                f\"Train Loss: {train_loss:.6f}, \"\n", "                f\"Val Loss: {val_loss:.6f}, \"\n", "                f\"Time: {elapsed:.2f}s\"\n", "            )\n", "    return train_losses, val_losses"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Train the model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["num_epochs = 20\n", "train_losses, val_losses = train_model(\n", "    model,\n", "    X_train_tensor,\n", "    y_train_tensor,\n", "    X_val_tensor,\n", "    y_val_tensor,\n", "    criterion,\n", "    optimizer,\n", "    num_epochs,\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Plot training and validation loss"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(10, 5))\n", "plt.plot(train_losses, label=\"Training Loss\")\n", "plt.plot(val_losses, label=\"Validation Loss\")\n", "plt.title(\"Training and Validation Loss\")\n", "plt.xlabel(\"Epoch\")\n", "plt.ylabel(\"Loss\")\n", "plt.legend()\n", "plt.grid(True)\n", "plt.savefig(\"training_validation_loss.pdf\")\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Function to predict future values"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def predict_future(model, initial_sequence, num_predictions=12):\n", "    model.eval()\n\n", "    # Start with the last known sequence\n", "    current_sequence = initial_sequence.clone()\n", "    predictions = []\n", "    h = None\n", "    with torch.no_grad():\n", "        for _ in range(num_predictions):\n", "            # Get prediction for next month\n", "            pred, h = model(current_sequence, h)\n", "            predictions.append(pred.cpu().numpy())\n\n", "            # Update sequence for next prediction (remove oldest, add prediction)\n", "            current_sequence = torch.cat(\n", "                [\n", "                    current_sequence[1:],  # Remove the first time step\n", "                    pred.unsqueeze(0),  # Add the prediction as the last time step\n", "                ],\n", "                dim=0,\n", "            )\n", "    return np.array(predictions)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Get the last sequence from the data for prediction"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["last_sequence = torch.FloatTensor(crime_matrix_scaled[-seq_length:]).to(device)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Make predictions for the next 12 months"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["num_future_months = 12\n", "future_scaled = predict_future(model, last_sequence, num_future_months)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Inverse transform the predictions to get actual crime counts"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["future_predictions = scaler.inverse_transform(future_scaled)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Create dataframe with predictions"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["prediction_df = pd.DataFrame()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Generate date range for future predictions"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["last_date = pd.to_datetime(f\"{time_points[-1]//12}-{time_points[-1]%12+1}-01\")\n", "future_dates = pd.date_range(start=last_date, periods=num_future_months + 1, freq=\"M\")[\n", "    1:\n", "]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Add predictions for each location to the dataframe"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for i, loc in enumerate(locations):\n", "    prediction_df[loc] = [max(0, round(val)) for val in future_predictions[:, i]]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["prediction_df.index = future_dates\n", "prediction_df.index.name = \"Date\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["Display sample of predictions"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"\\nSample predictions for the next 12 months:\")\n", "print(prediction_df.iloc[:, :5].head())  # Show first 5 locations, first 5 months"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Calculate total crime counts per month"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["prediction_df[\"Total\"] = prediction_df.sum(axis=1)\n", "print(\"\\nPredicted total crime counts per month:\")\n", "print(prediction_df[\"Total\"])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Plot predictions for a few locations"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(15, 10))\n", "num_plots = 5"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Find locations with significant activity"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["active_locations = []\n", "for i in range(len(locations)):\n", "    if np.max(crime_matrix[:, i]) > 5:  # Locations with at least some activity\n", "        active_locations.append(i)\n", "        if len(active_locations) >= num_plots:\n", "            break"]}, {"cell_type": "markdown", "metadata": {}, "source": ["If not enough active locations found, just take the first few"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if len(active_locations) < num_plots:\n", "    active_locations = list(range(min(num_plots, len(locations))))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Plot each location"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for i, loc_idx in enumerate(active_locations):\n", "    loc = locations[loc_idx]\n\n", "    # Historical data\n", "    historical = crime_matrix[:, loc_idx]\n\n", "    # Time points for x-axis\n", "    time_indices = np.arange(len(historical) + num_future_months)\n", "    plt.subplot(num_plots, 1, i + 1)\n\n", "    # Plot historical data\n", "    plt.plot(\n", "        time_indices[: len(historical)], historical, label=\"Historical\", color=\"blue\"\n", "    )\n\n", "    # Plot predictions\n", "    plt.plot(\n", "        time_indices[len(historical) :],\n", "        future_predictions[:, loc_idx],\n", "        label=\"Predicted\",\n", "        color=\"red\",\n", "        linestyle=\"--\",\n", "    )\n\n", "    # Add a vertical line separating historical and predicted data\n", "    plt.axvline(x=len(historical) - 1, color=\"gray\", linestyle=\"--\")\n", "    plt.title(f\"Crime Count for {loc}\")\n", "    plt.legend()\n", "    plt.grid(True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.tight_layout()\n", "plt.savefig(\"location_predictions.pdf\")\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Export predictions to CSV"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["prediction_df.to_csv(\"crime_predictions.csv\")\n", "print(\"\\nPredictions saved to 'crime_predictions.csv'\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Save the model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["torch.save(\n", "    {\n", "        \"model_state_dict\": model.state_dict(),\n", "        \"optimizer_state_dict\": optimizer.state_dict(),\n", "        \"scaler\": scaler,\n", "        \"locations\": locations,\n", "    },\n", "    \"crime_prediction_model.pth\",\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"Model saved to 'crime_prediction_model.pth'\")"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}