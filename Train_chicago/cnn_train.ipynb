{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd42e811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Load data (make sure to adjust the path if needed)\n",
    "df = pd.read_csv('time_series_data.csv')\n",
    "\n",
    "# Split into train and test\n",
    "df_train = df[df[\"Year\"] <= 2023]\n",
    "df_test = df[df[\"Year\"] > 2023]\n",
    "\n",
    "# Columns and feature selection\n",
    "categorical_cols = [\"location_name\"]\n",
    "numerical_cols = [\"sin_month\", \"cos_month\", \"Year\", \"Month\", \"num_days\", \"holiday_num\"]\n",
    "numerical_features = [\n",
    "    \"crime_count\",\n",
    "    \"crime_pct_change\",\n",
    "    \"morning\",\n",
    "    \"afternoon\",\n",
    "    \"evening\",\n",
    "    \"night\",\n",
    "    \"domestic\",\n",
    "    \"arrest\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3eb1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [1, 2, 3, 6, 12]:\n",
    "    for j in numerical_features:\n",
    "        numerical_cols.append(f\"{j}_lag{i}\")\n",
    "for i in [3, 6]:\n",
    "    for j in numerical_features:\n",
    "        numerical_cols.append(f\"{j}_ma{i}\")\n",
    "\n",
    "# Split features and target\n",
    "X_train = df_train[categorical_cols + numerical_cols]\n",
    "y_train = df_train[\"crime_count\"]\n",
    "X_test = df_test[categorical_cols + numerical_cols]\n",
    "y_test = df_test[\"crime_count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9680e9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing pipeline\n",
    "cat_pipe = Pipeline([\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numerical_cols),\n",
    "        (\"cat_pipe\", cat_pipe, categorical_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Apply preprocessing to training and testing data\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_processed, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_processed, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "\n",
    "# Custom dataset class for PyTorch\n",
    "class CrimeDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_dataset = CrimeDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = CrimeDataset(X_test_tensor, y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4195561f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader for batch processing\n",
    "batch_size = 8\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Attention Layer Implementation\n",
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "        self.query = nn.Linear(input_dim, input_dim)\n",
    "        self.key = nn.Linear(input_dim, input_dim)\n",
    "        self.value = nn.Linear(input_dim, input_dim)\n",
    "        self.scale = None  # We will initialize scale inside forward\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Get the device of the input tensor x\n",
    "        device = x.device\n",
    "        \n",
    "        # Initialize scale on the same device as input tensor\n",
    "        if self.scale is None:\n",
    "            self.scale = torch.sqrt(torch.FloatTensor([x.size(-1)])).to(device)\n",
    "        \n",
    "        # Calculate query, key, and value\n",
    "        Q = self.query(x)  # (batch_size, seq_len, input_dim)\n",
    "        K = self.key(x)\n",
    "        V = self.value(x)\n",
    "        \n",
    "        # Compute attention scores\n",
    "        attention_scores = torch.matmul(Q, K.transpose(-2, -1)) / self.scale\n",
    "        attention_weights = F.softmax(attention_scores, dim=-1)\n",
    "        \n",
    "        # Apply attention to values\n",
    "        attended_values = torch.matmul(attention_weights, V)\n",
    "        return attended_values\n",
    "\n",
    "class CrimePredictionModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(CrimePredictionModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, 1)  # Output layer for crime count prediction\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.2)  # Adding dropout for regularization\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.fc4(x)  # No activation function here (regression task)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800afa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with tqdm progress bar\n",
    "# Training function with evaluation and saving the best model\n",
    "def train_and_evaluate_model(model, train_loader, test_loader, criterion, optimizer, num_epochs=10, save_path=\"best_model.pth\"):\n",
    "    best_mae = float('inf')  # Start with a very high RMSE\n",
    "    best_epoch = 0\n",
    "    best_model = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        # Train for one epoch\n",
    "        for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.squeeze(), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "        # Evaluate after each epoch\n",
    "        model.eval()\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in tqdm(test_loader, desc=\"Evaluating\", leave=False):\n",
    "                outputs = model(inputs)\n",
    "                y_true.extend(labels.numpy())\n",
    "                y_pred.extend(outputs.squeeze().numpy())\n",
    "\n",
    "        # Convert to numpy arrays\n",
    "        y_true = np.array(y_true)\n",
    "        y_pred = np.array(y_pred)\n",
    "\n",
    "        # Compute RMSE, R², and MAE\n",
    "        rmse = np.sqrt(mean_squared_error(y_true, y_pred))  # Root Mean Squared Error\n",
    "        r2 = r2_score(y_true, y_pred)  # R² (Coefficient of Determination)\n",
    "        mae = mean_absolute_error(y_true, y_pred)  # Mean Absolute Error\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] RMSE: {rmse}, R²: {r2}, MAE: {mae}\")\n",
    "\n",
    "        # Save the best model based on RMSE, MAE, or R² (whichever is best)\n",
    "        if mae < best_mae:\n",
    "            best_mae= mae\n",
    "            best_epoch = epoch + 1\n",
    "            best_model = model.state_dict()  # Save the model's state_dict (weights)\n",
    "\n",
    "    # Save the best model after training\n",
    "    if best_model is not None:\n",
    "        torch.save(best_model, save_path)\n",
    "        print(f\"Best model saved at epoch {best_epoch} with RMSE: {rmse} with MAE: {best_mae} with R²: {r2}\")\n",
    "\n",
    "# Initialize the model and optimizer\n",
    "input_dim = X_train_processed.shape[1]  # Number of input features\n",
    "model = CrimePredictionModel(input_dim)\n",
    "criterion = nn.MSELoss()  # Mean Squared Error for regression\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# # Train and evaluate the model\n",
    "train_and_evaluate_model(model, train_loader, test_loader, criterion, optimizer, num_epochs=800, save_path=\"best_model.pth\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
